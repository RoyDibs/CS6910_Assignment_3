# -*- coding: utf-8 -*-
"""train_model.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1xS9vlHSJXHGd4B2MwaMyJG5D8H_csSuD
"""

import torch
import torch.nn as nn
import torch.nn.functional as F
import torch.optim as optim
import numpy as np
import random
import argparse

from data_loader_functions import  Language, load_data, get_languages, get_cell, get_optimizer
from model import Encoder, AttentionDecoder
from data_convert import tensor_from_word, indexes_from_word, tensors_from_pair
from train import train
from train_single import train_single
from test import test_validate

parser = argparse.ArgumentParser(description="Train neural network with specified hyperparameters.")


parser.add_argument("-em_z", "--embed_size", type=int, default=32, help="Embedding size for word vectors")
parser.add_argument("-hd_z", "--hidden_size", type=int, default=512, help="Hidden size for LSTM/GRU cells")
parser.add_argument("-cell", "--cell_type", default="RNN", choices=["LSTM", "GRU", "RNN"], help="Type of recurrent cell (LSTM or GRU)")
parser.add_argument("-n_l","--num_layers", type=int, default=1, help="Number of stacked LSTM/GRU layers")
parser.add_argument("-dp", "--dropout", type=float, default=0, help="Dropout rate for regularization")
parser.add_argument("-lr", "--learning_rate", type=float, default=0.001, help="Learning rate for the optimizer")
parser.add_argument("-o", "--optimizer", default='ADAM', choices=["ADAM", "SDG"], help="Optimizer used for training (currently only Adam supported)")
parser.add_argument("-e","--epochs", type=int, default=5, help="Number of epochs to train the network")
parser.add_argument("-tfr","--teacher_forcing_ratio", type=float, default=0.5, help="Teacher forcing ratio")
parser.add_argument("-m_l","--max_length", type=int, default=50, help="Maximum length")
parser.add_argument("-dir","--data_dir", type=str, required=True, help="Directory path containing the training dataset")

args = parser.parse_args()

# Set device
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")

class Translator:
    def __init__(self, lang: str, params: dict, path):
        self.lang = lang
        self.input_lang, self.output_lang, self.pairs = get_languages(self.lang, path)
        self.input_size = self.input_lang.n_chars
        self.output_size = self.output_lang.n_chars
        self.training_pairs = [tensors_from_pair(self.input_lang, self.output_lang, pair) for pair in self.pairs]
        self.encoder = Encoder(input_size=self.input_size, embed_size=params['embed_size'], hidden_size=params['hidden_size'], cell_type=params['cell_type'], num_layers=params['num_layers'], dropout=params['dropout']).to(device)
        self.decoder = AttentionDecoder(output_size=self.output_size, embed_size=params['embed_size'], hidden_size=params['hidden_size'], cell_type=params['cell_type'], num_layers=params['num_layers'], dropout=params['dropout']).to(device)
        self.encoder_optimizer = get_optimizer(params['optimizer'])(self.encoder.parameters(), lr=params['learning_rate'])
        self.decoder_optimizer = get_optimizer(params['optimizer'])(self.decoder.parameters(), lr=params['learning_rate'])
        self.criterion = nn.NLLLoss()
        self.teacher_forcing_ratio = params['teacher_forcing_ratio']
        self.max_length = params['max_length']
        self.PRINT_EVERY = 40000
        self.PLOT_EVERY = 40000

    def train(self, iters=-1):
        plot_losses = []
        print_loss_total = 0
        plot_loss_total = 0
        random.shuffle(self.training_pairs)
        iters = len(self.training_pairs) if iters == -1 else iters
        for iter in range(1, iters):
            training_pair = self.training_pairs[iter - 1]
            input_tensor = training_pair[0]
            target_tensor = training_pair[1]
            loss = train_single(self, input_tensor, target_tensor)
            print_loss_total += loss
            plot_loss_total += loss
            if iter % self.PRINT_EVERY == 0:
                print_loss_avg = print_loss_total / self.PRINT_EVERY
                print_loss_total = 0
                print("Loss: {:.4f} | Iterations: {}".format(print_loss_avg, iter))
            if iter % self.PLOT_EVERY == 0:
                plot_loss_avg = plot_loss_total / self.PLOT_EVERY
                plot_losses.append(plot_loss_avg)
                plot_loss_total = 0
        return plot_losses

    def evaluate(self, word):
        return evaluate(self, word)

    def test_validate(self, type:str, path):
        return test_validate(self, type, path)


config = {

    'embed_size': args.embed_size,
    'hidden_size': args.hidden_size,
    'cell_type': args.cell_type,
    'num_layers': args.num_layers,
    'dropout': args.dropout,
    'learning_rate': args.learning_rate,
    'optimizer': args.optimizer,
    'epochs': args.epochs,
    'teacher_forcing_ratio': args.teacher_forcing_ratio,
    'max_length': args.max_length,
}

path = args.data_dir


model = Translator('hin', config, path)
epochs = config['epochs']
old_validation_accuracy = 0
for epoch in range(epochs):
    print("Epoch: {}".format(epoch + 1))
    plot_losses = model.train()
    training_loss = sum(plot_losses) / len(plot_losses)
    validation_accuracy = model.test_validate('valid', path)
    print("training_loss: {:.4f}".format(training_loss))
    print("validation_accuracy: {:.4f}".format(validation_accuracy))
    if epoch > 0:
        if validation_accuracy < 0.0001:
            break
        if validation_accuracy < 0.9 * old_validation_accuracy:
            break
    old_validation_accuracy = validation_accuracy

test_accuracy = model.test_validate('test', path)
print("Test Accuracy: {:.4f}".format(test_accuracy))